var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = Maxnet","category":"page"},{"location":"#Maxnet","page":"Home","title":"Maxnet","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for Maxnet.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [Maxnet]","category":"page"},{"location":"#Maxnet.MaxnetBinaryClassifier","page":"Home","title":"Maxnet.MaxnetBinaryClassifier","text":"MaxnetBinaryClassifier\n\nA model type for fitting a maxnet model using `MLJ`.\n    \nUse `MaxnetBinaryClassifier()` to create an instance with default parameters, or use keyword arguments to specify parameters.\n\nAll keywords are passed to `maxnet` when calling `fit!` on a machine of this model type.\nSee the documentation of [`maxnet`](@ref) for the parameters and their defaults.\n\n# Example\n```jldoctest\nusing Maxnet, MLJBase\np_a, env = Maxnet.bradypus()\n\nmach = machine(MaxnetBinaryClassifier(features = \"lqp\"), env, categorical(p_a))\nfit!(mach)\nyhat = MLJBase.predict(mach, env)\n# output\n```\n\n\n\n\n\n","category":"type"},{"location":"#Maxnet.complexity-Tuple{Maxnet.MaxnetModel}","page":"Home","title":"Maxnet.complexity","text":"Get the number of non-zero coefficients in the model\n\n\n\n\n\n","category":"method"},{"location":"#Maxnet.default_features-Tuple{Any}","page":"Home","title":"Maxnet.default_features","text":"default_features(np)\n\nTakes the number of presences np and returns a Vector of AbstractFeatureClasss that are used my maxent as default.\n\nIf np is less than ten, then only LinearFeature and CategoricalFeature are used. If it is at least 10, then QuadraticFeature is additionally used. If it is at least 15, then HingeFeature is additionally used. If it is at least 80, then ProductFeature is additionally used.\n\n\n\n\n\n","category":"method"},{"location":"#Maxnet.maxnet-Tuple{BitVector, Any}","page":"Home","title":"Maxnet.maxnet","text":"maxnet(\n    presences, predictors; \n    features, regularization_multiplier, regularization_function,\n    addsamplestobackground, weight_factor, backend, \n    kw...\n)\n\nFit a model using the maxnet algorithm.\n\nArguments\n\npresences: A BitVector where presences are true and background samples are false\npredictors: A Tables.jl-compatible table of predictors. Categorical predictors should be CategoricalVectors\n\nKeywords\n\nfeatures: Either a Vector of AbstractFeatureClass to be used in the model,    or a String where \"l\" = linear and categorical, \"q\" = quadratic, \"p\" = product, \"t\" = threshold, \"h\" = hinge (e.g. \"lqh\"); or   By default, the features are based on the number of presences are used. See default_features\nregularization_multiplier: A constant to adjust regularization, where a higher regularization_multiplier results in a higher penalization for features\nregularization_function: A function to compute a regularization for each feature. A default regularization_function is built in.\naddsamplestobackground: A boolean, where true adds the background samples to the predictors. Defaults to true.\nn_knots: the number of knots used for Threshold and Hinge features. Defaults to 50. Ignored if there are neither Threshold nor Hinge features\nweight_factor: A Float64 value to adjust the weight of the background samples. Defaults to 100.0.\nbackend: Either LassoBackend() or GLMNetBackend(), to use either Lasso.jl or GLMNet.jl to fit the model.\n\nLasso.jl is written in pure julia, but can be slower with large model matrices (e.g. when hinge is enabled). Defaults to LassoBackend.\n\nkw...: Further arguments to be passed to Lasso.fit or GLMNet.glmnet\n\nReturns\n\nmodel: A model of type MaxnetModel\n\nExamples\n\nusing Maxnet\np_a, env = Maxnet.bradypus();\nbradypus_model = maxnet(p_a, env; features = \"lq\", backend = GLMNetBackend())\n\nFit Maxnet model\nFeatures classes: Maxnet.AbstractFeatureClass[LinearFeature(), CategoricalFeature(), QuadraticFeature()]\nEntropy: 6.114650341746531\nModel complexity: 21\nVariables selected: [:frs6190_ann, :h_dem, :pre6190_l1, :pre6190_l10, :pre6190_l4, :pre6190_l7, :tmn6190_ann, :vap6190_ann, :ecoreg, :cld6190_ann, :dtr6190_ann, :tmx6190_ann]\n\n\n\n\n\n","category":"method"},{"location":"#Maxnet.predict-Tuple{Maxnet.MaxnetModel, Any}","page":"Home","title":"Maxnet.predict","text":"predict(m, x; link, clamp)\n\nUse a maxnet model to predict on new data.\n\nArguments\n\nm: a MaxnetModel as returned by maxnet\nx: a Tables.jl-compatible table of predictors. All columns that were used to fit m should be present in x\n\nKeywords\n\nlink: the link function used. Defaults to CloglogLink(), which is the default on the Maxent Java appliation since version 4.3.   Alternatively, LogitLink() was the Maxent default on earlier versions.    To get exponential output, which can be interpreted as predicted abundance, use LogLink()   IdentityLink() returns the exponent without any transformation.\nclamp: If true, values in x will be clamped to the range the model was trained on. Defaults to false.\n\nReturns\n\nA Vector with the resulting predictions.\n\nExample\n\nusing Maxnet\np_a, env = Maxnet.bradypus();\nbradypus_model = maxnet(p_a, env; features = \"lq\")\nprediction = Maxnet.predict(bradypus_model, env)\n\n\n\n\n\n","category":"method"}]
}
