var documenterSearchIndex = {"docs":
[{"location":"reference/api/#API","page":"API reference","title":"API","text":"","category":"section"},{"location":"reference/api/#Index","page":"API reference","title":"Index","text":"","category":"section"},{"location":"reference/api/#Functions","page":"API reference","title":"Functions","text":"","category":"section"},{"location":"reference/api/#Types","page":"API reference","title":"Types","text":"","category":"section"},{"location":"reference/api/#Maxnet.complexity-Tuple{Maxnet.MaxnetModel}","page":"API reference","title":"Maxnet.complexity","text":"Get the number of non-zero coefficients in the model\n\n\n\n\n\n","category":"method"},{"location":"reference/api/#Maxnet.default_features-Tuple{Any}","page":"API reference","title":"Maxnet.default_features","text":"default_features(np)\n\nTakes the number of presences np and returns a Vector of AbstractFeatureClasss that are used my maxent as default.\n\nIf np is less than ten, then only LinearFeature and CategoricalFeature are used. If it is at least 10, then QuadraticFeature is additionally used. If it is at least 15, then HingeFeature is additionally used. If it is at least 80, then ProductFeature is additionally used.\n\n\n\n\n\n","category":"method"},{"location":"reference/api/#Maxnet.maxnet-Tuple{BitVector, Any}","page":"API reference","title":"Maxnet.maxnet","text":"maxnet(\n    p_a, X; \n    features, regularization_multiplier, regularization_function,\n    addsamplestobackground, weight_factor, \n    kw...\n)\n\nFit a model using the maxnet algorithm.\n\nArguments\n\np_a: A BitVector where presences are true and background samples are false\nX: A Tables.jl-compatible table of predictors. Categorical predictors should be CategoricalVectors\n\nKeywords\n\nfeatures: Either a Vector of AbstractFeatureClass to be used in the model,    or a String where \"l\" = linear and categorical, \"q\" = quadratic, \"p\" = product, \"t\" = threshold, \"h\" = hinge (e.g. \"lqh\"); or   By default, the features are based on the number of presences are used. See default_features\nregularization_multiplier: A constant to adjust regularization, where a higher regularization_multiplier results in a higher    penalization for features and therefore less overfitting.\nregularization_function: A function to compute a regularization for each feature. A default regularization_function is built in   and should be used in most cases.\naddsamplestobackground: Whether to add presence values to the background. Defaults to true.\nn_knots: the number of knots used for Threshold and Hinge features. Defaults to 50. Ignored if there are neither Threshold nor Hinge features\nweight_factor: A Float64 value to adjust the weight of the background samples. Defaults to 100.0.\nkw...: Further arguments to be passed to GLMNet.glmnet\n\nReturns\n\nmodel: A model of type MaxnetModel\n\nExamples\n\nusing Maxnet\np_a, env = Maxnet.bradypus();\nbradypus_model = maxnet(p_a, env; features = \"lq\")\n\n# Output\nFit Maxnet model\nFeatures classes: Maxnet.AbstractFeatureClass[LinearFeature(), CategoricalFeature(), QuadraticFeature()]\nEntropy: 6.114650341746531\nModel complexity: 21\nVariables selected: [:frs6190_ann, :h_dem, :pre6190_l1, :pre6190_l10, :pre6190_l4, :pre6190_l7, :tmn6190_ann, :vap6190_ann, :ecoreg, :cld6190_ann, :dtr6190_ann, :tmx6190_ann]\n\n\n\n\n\n","category":"method"},{"location":"reference/api/#StatsAPI.predict-Tuple{Maxnet.MaxnetModel, Any}","page":"API reference","title":"StatsAPI.predict","text":"predict(m, X; link, clamp)\n\nUse a maxnet model to predict on new data.\n\nArguments\n\nm: a MaxnetModel as returned by maxnet\nX: a Tables.jl-compatible table of predictors. All columns that were used to fit m should be present in X\n\nKeywords\n\nlink: the link function used. Defaults to CloglogLink(), which is the default on the Maxent Java appliation since version 4.3.   Alternatively, LogitLink() was the Maxent default on earlier versions.    To get exponential output, which can be interpreted as predicted abundance, use LogLink()   IdentityLink() returns the exponent without any transformation.\nclamp: If true, values in x will be clamped to the range the model was trained on. Defaults to false.\n\nReturns\n\nA Vector with the resulting predictions.\n\nExample\n\nusing Maxnet\np_a, env = Maxnet.bradypus();\nbradypus_model = maxnet(p_a, env; features = \"lq\")\nprediction = predict(bradypus_model, env)\n\n\n\n\n\n","category":"method"},{"location":"reference/api/#Maxnet.MaxnetBinaryClassifier","page":"API reference","title":"Maxnet.MaxnetBinaryClassifier","text":"MaxnetBinaryClassifier\n\nA model type for constructing a Maxnet, based on Maxnet.jl, and implementing the MLJ model interface.\n\nFrom MLJ, the type can be imported using\n\nMaxnetBinaryClassifier = @load MaxnetBinaryClassifier pkg=Maxnet\n\nDo model = MaxnetBinaryClassifier() to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in MaxnetBinaryClassifier(features=...).\n\nTraining data\n\nIn MLJ or MLJBase, bind an instance model to data with\n\nmach = machine(model, X, y)\n\nwhere\n\nX: any table of input features (eg, a DataFrame) whose columns each have one of the following element scitypes: Continuous or <:Multiclass. Check scitypes with schema(X).\ny: is the target, which can be any AbstractVector whose element scitype is <:Binary. The first class should refer to background values, and the second class to presence values.\n\nHyper-parameters\n\nfeatures: Specifies which features classes to use in the model, e.g. \"lqh\" for linear, quadratic and hinge features.    See also Maxnet.maxnet\nregularization_multiplier = 1.0: 'Adjust how tight the model will fit. Increasing this will reduce overfitting.\nregularization_function: A function to compute the regularization of each feature class. Defaults to Maxnet.default_regularization\naddsamplestobackground = true: Controls wether to add presence values to the background.\nn_knots = 50: The number of knots used for Threshold and Hinge features. A higher number gives more flexibility for these features.\nweight_factor = 100.0: A Float64 value to adjust the weight of the background samples.\nlink = Maxnet.CloglogLink(): The link function to use when predicting. See Maxnet.predict \nclamp = false: Clamp values passed to MLJBase.predict to the range the model was trained on.\n\nOperations\n\npredict(mach, Xnew): return predictions of the target given features Xnew having the same scitype as X above. Predictions are  probabilistic and can be interpreted as the probability of presence.\n\nFitted Parameters\n\nThe fields of fitted_params(mach) are:\n\nfitresult: A Tuple where the first entry is the Maxnet.MaxnetModel returned by the Maxnet algorithm   and the second the entry is the classes of y\n\nReport\n\nThe fields of report(mach) are:\n\nselected_variables: A Vector of Symbols of the variables that were selected.\nselected_features: A Vector of Maxnet.ModelMatrixColumn with the features that were selected.\ncomplexity: the number of selected features in the model.\n\nExample\n\nusing MLJBase, Maxnet\np_a, env = Maxnet.bradypus()\ny = coerce(p_a, Binary)\nX = coerce(env, Count => Continuous)\n\nmach = machine(MaxnetBinaryClassifier(features = \"lqp\"), X, y)\nfit!(mach)\nyhat = MLJBase.predict(mach, env)\n\n\n\n\n\n\n","category":"type"},{"location":"usage/quickstart/#Installation","page":"Quick start","title":"Installation","text":"Install the latest version of Maxnet.jl by running\n\n]\nadd Maxnet","category":"section"},{"location":"usage/quickstart/#Basic-usage","page":"Quick start","title":"Basic usage","text":"","category":"section"},{"location":"usage/quickstart/#Fit-a-model","page":"Quick start","title":"Fit a model","text":"Use the maxnet function to generate a model. maxnet takes a BitVector as its first arguments, where true encodes presences points and false background points. As its second argument, it takes any Tables.jl-compatible data structure with predictor variables. Categorical variables are treated differently than numeric variables and must be a CategoricalVector. Keyword arguments are used to tweak model settings.\n\npredict takes a model generated by maxnet and any Tables.jl-compatible data structure.\n\nMaxnet.jl comes with a sample dataset of presences and background points for the sloth species Bradypus variegatus (see Philips et al., 2006 for details).\n\nThe following code fits a maxnet model for Bradypus variegatus with default settings and generates the predicted suitability at each point.\n\nusing Maxnet\np_a, env = Maxnet.bradypus()\nbradypus_model = maxnet(p_a, env)\nprediction = predict(bradypus_model, env)\n\nThere are numerous settings that can be tweaked to change the model fit. These are documentated in the documentation for the maxnet and predict functions.","category":"section"},{"location":"usage/quickstart/#Model-settings","page":"Quick start","title":"Model settings","text":"The two most important settings to change when running Maxnet is the feature classes selected and the regularization factor.\n\nBy default, the feature classes selected depends on the number of presence points, see default_features. To set them manually, specify the features keyword using either a Vector of AbstractFeatureClass, or a string, where l represents LinearFeature and CategoricalFeature, q represents QuadraticFeature, p represents ProductFeature, t represents ThresholdFeature and h represents HingeFeature. \n\nFor example:\n\nmodel1 = maxnet(p_a, env; features = [LinearFeature(), CategoricalFeature(), QuadraticFeature()])\nmodel2 = maxnet(p_a, env; features = \"lqph\")\n\nThe regularization multiplier controls how much the algorithms penalizes complex models. A higher regularization multiplier will result in a simpler model with fewer features.\n\nmodel3 = maxnet(p_a, env; features = \"lqph\", regularization_multiplier = 10.0)\n\nThe number of features selected is shown when a model is printed in the REPL and can be accessed using complexity. Here complexity(model2) gives 48 and complexity(model3) gives 13.","category":"section"},{"location":"#Maxnet","page":"Home","title":"Maxnet","text":"(Image: Stable) (Image: Dev) (Image: Build Status) (Image: Coverage)\n\nThis is a Julia implementation of the maxnet algorithm, with all core functionality in the original R package.\n\nMaxnet transforms input data in various ways and then uses the GLMnet algorithm to fit a lasso path, selecting the best variables and transformations.\n\nMaxnet is closely related to the Java MaxEnt application, which is widely used in species distribution modelling. It was developped by Steven Philips. See this publication for more details about maxnet.\n\nAlso see the Maxent page on the site of the American Museum for Natural History.\n\nDocumentation for Maxnet.\n\n","category":"section"},{"location":"usage/mlj/#Integration-with-MLJ","page":"MLJ","title":"Integration with MLJ","text":"Maxnet.jl integrates with the MLJ ecosystem.\n\nSee MLJs project page for more info about MLJ.\n\nTo use Maxnet with MLJ, initialise a model by calling MaxnetBinaryClassifier, which accepts any arguments otherwise passed to maxnet. The model can then be used with MLJ's machine.\n\nFor example:\n\nusing Maxnet: MaxnetBinaryClassifier, bradypus\nusing MLJBase\n\n# sample data\ny, X = bradypus()\n\n# define a model\nmodel = MaxnetBinaryClassifier(features = \"lq\")\n\n# construct a machine\nmach = machine(model, X, categorical(y))\n\n# partition data\ntrain, test = partition(eachindex(y), 0.7, shuffle=true)\n\n# fit the machine to the data\nfit!(mach; rows = train)\n\n# predict on test data\npred_test = predict(mach; rows = test)\n\n# predict on some new dataset\npred = predict(mach, X)","category":"section"}]
}
